{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification\n",
    "\n",
    "(reference Chapter 4 ISLR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#basic imports\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import sklearn.linear_model as skl_lm\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn import neighbors\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first load in the Student Default database. See the documentation here: https://www.rdocumentation.org/packages/ISLR/versions/1.2/topics/Default\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>default</th>\n",
       "      <th>student</th>\n",
       "      <th>balance</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>729.526495</td>\n",
       "      <td>44361.625074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>817.180407</td>\n",
       "      <td>12106.134700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>1073.549164</td>\n",
       "      <td>31767.138947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>529.250605</td>\n",
       "      <td>35704.493935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>785.655883</td>\n",
       "      <td>38463.495879</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 default student      balance        income\n",
       "0           1      No      No   729.526495  44361.625074\n",
       "1           2      No     Yes   817.180407  12106.134700\n",
       "2           3      No      No  1073.549164  31767.138947\n",
       "3           4      No      No   529.250605  35704.493935\n",
       "4           5      No      No   785.655883  38463.495879"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('C:/Users/cutalnaf/Desktop/Data/Default.xlsx')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x223939c3b50>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "c_palette = {'No':'lightblue', 'Yes':'orange'}\n",
    "\n",
    "f,(ax1,ax2)=plt.subplots(1,2)\n",
    "#plt.tight_layout()\n",
    "plt.tight_layout(pad=1, w_pad=5, h_pad=1.0)\n",
    "sns.boxplot('default', 'balance', data=df, orient='v',ax=ax1, palette=c_palette)\n",
    "sns.boxplot('default', 'income', data=df, orient='v',ax=ax2, palette=c_palette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>default</th>\n",
       "      <th>student</th>\n",
       "      <th>balance</th>\n",
       "      <th>income</th>\n",
       "      <th>default2</th>\n",
       "      <th>student2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>729.526495</td>\n",
       "      <td>44361.625074</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>817.180407</td>\n",
       "      <td>12106.134700</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>1073.549164</td>\n",
       "      <td>31767.138947</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>529.250605</td>\n",
       "      <td>35704.493935</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>785.655883</td>\n",
       "      <td>38463.495879</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>919.588530</td>\n",
       "      <td>7491.558572</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>825.513331</td>\n",
       "      <td>24905.226578</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>808.667504</td>\n",
       "      <td>17600.451344</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>1161.057854</td>\n",
       "      <td>37468.529288</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29275.268293</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21871.073089</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1220.583753</td>\n",
       "      <td>13268.562221</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>237.045114</td>\n",
       "      <td>28251.695345</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>606.742343</td>\n",
       "      <td>44994.555849</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>1112.968401</td>\n",
       "      <td>23810.174050</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0 default student      balance        income  default2  student2\n",
       "0            1      No      No   729.526495  44361.625074         0         0\n",
       "1            2      No     Yes   817.180407  12106.134700         0         1\n",
       "2            3      No      No  1073.549164  31767.138947         0         0\n",
       "3            4      No      No   529.250605  35704.493935         0         0\n",
       "4            5      No      No   785.655883  38463.495879         0         0\n",
       "5            6      No     Yes   919.588530   7491.558572         0         1\n",
       "6            7      No      No   825.513331  24905.226578         0         0\n",
       "7            8      No     Yes   808.667504  17600.451344         0         1\n",
       "8            9      No      No  1161.057854  37468.529288         0         0\n",
       "9           10      No      No     0.000000  29275.268293         0         0\n",
       "10          11      No     Yes     0.000000  21871.073089         0         1\n",
       "11          12      No     Yes  1220.583753  13268.562221         0         1\n",
       "12          13      No      No   237.045114  28251.695345         0         0\n",
       "13          14      No      No   606.742343  44994.555849         0         0\n",
       "14          15      No      No  1112.968401  23810.174050         0         0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#recode the categorical values in default and student columsn to numerals\n",
    "#by adding the 'default2' and 'student2' columns\n",
    "df['default2'] = df.default.factorize()[0]\n",
    "df['student2'] = df.student.factorize()[0]\n",
    "df.head(15)\n",
    "#verify that No is coded as 0 and Yes = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression (Scikit-Learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(solver='newton-cg')\n",
      "classes:  [0 1]\n",
      "coefficients:  [[0.00549891]]\n",
      "intercept : [-10.65132237]\n"
     ]
    }
   ],
   "source": [
    "X_train = df.balance.values.reshape(-1,1) \n",
    "y = df.default2\n",
    "clf = skl_lm.LogisticRegression(solver='newton-cg')\n",
    "X_train = df.balance.values.reshape(-1,1)\n",
    "clf.fit(X_train,y)\n",
    "print(clf)\n",
    "print('classes: ',clf.classes_)\n",
    "print('coefficients: ',clf.coef_)\n",
    "print('intercept :', clf.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression (Statsmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.079823\n",
      "         Iterations 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coef.</th>\n",
       "      <th>Std.Err.</th>\n",
       "      <th>z</th>\n",
       "      <th>P&gt;|z|</th>\n",
       "      <th>[0.025</th>\n",
       "      <th>0.975]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>const</th>\n",
       "      <td>-10.651331</td>\n",
       "      <td>0.361169</td>\n",
       "      <td>-29.491287</td>\n",
       "      <td>3.723665e-191</td>\n",
       "      <td>-11.359208</td>\n",
       "      <td>-9.943453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>balance</th>\n",
       "      <td>0.005499</td>\n",
       "      <td>0.000220</td>\n",
       "      <td>24.952404</td>\n",
       "      <td>2.010855e-137</td>\n",
       "      <td>0.005067</td>\n",
       "      <td>0.005931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Coef.  Std.Err.          z          P>|z|     [0.025    0.975]\n",
       "const   -10.651331  0.361169 -29.491287  3.723665e-191 -11.359208 -9.943453\n",
       "balance   0.005499  0.000220  24.952404  2.010855e-137   0.005067  0.005931"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = sm.add_constant(df.balance)\n",
    "est = sm.Logit(y, X_train).fit()\n",
    "\n",
    "est.summary2().tables[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.145434\n",
      "         Iterations 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coef.</th>\n",
       "      <th>Std.Err.</th>\n",
       "      <th>z</th>\n",
       "      <th>P&gt;|z|</th>\n",
       "      <th>[0.025</th>\n",
       "      <th>0.975]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>const</th>\n",
       "      <td>-3.504128</td>\n",
       "      <td>0.070713</td>\n",
       "      <td>-49.554094</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.642723</td>\n",
       "      <td>-3.365532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>student2</th>\n",
       "      <td>0.404887</td>\n",
       "      <td>0.115019</td>\n",
       "      <td>3.520177</td>\n",
       "      <td>0.000431</td>\n",
       "      <td>0.179454</td>\n",
       "      <td>0.630320</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Coef.  Std.Err.          z     P>|z|    [0.025    0.975]\n",
       "const    -3.504128  0.070713 -49.554094  0.000000 -3.642723 -3.365532\n",
       "student2  0.404887  0.115019   3.520177  0.000431  0.179454  0.630320"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df.default2\n",
    "X_train = sm.add_constant(df.student2)\n",
    "est = sm.Logit(y, X_train).fit()\n",
    "\n",
    "est.summary2().tables[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question \n",
    "\n",
    "1. Explain the values obtained especially in relation to the Z and p values\n",
    "2. Obtain the results using student column and explain the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer\n",
    "1. Explain the values obtained especially in relation to the Z and p values. \n",
    "For the Default data, estimated coefficients of the logistic regression model that predicts the probability of default using balance. A one-unit increase in balance is associated with an increase in the log odds of default by 0.0055 units. \n",
    "The p-value associated with balance variable is tiny, we can reject H0. In other words, we conclude that there is indeed an association between balance and probability of default. \n",
    "\n",
    "2. Obtain the results using student column and explain the results. \n",
    "For the Default data, estimated coefficients of the logistic regression model that predicts the probability of default using student status. Student status is encoded as a dummy variable, with a value of 1 for a student and a value of 0 for a non-student, and represented by the variable student2 in the table.\n",
    "The coefficient associated with the dummy variable is positive, and the associated p-value is statistically significant. This indicates that\n",
    "students tend to have higher default probabilities than non-students. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Logistic Regression (Statsmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.078577\n",
      "         Iterations 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coef.</th>\n",
       "      <th>Std.Err.</th>\n",
       "      <th>z</th>\n",
       "      <th>P&gt;|z|</th>\n",
       "      <th>[0.025</th>\n",
       "      <th>0.975]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>const</th>\n",
       "      <td>-10.869045</td>\n",
       "      <td>0.492273</td>\n",
       "      <td>-22.079320</td>\n",
       "      <td>4.995499e-108</td>\n",
       "      <td>-11.833882</td>\n",
       "      <td>-9.904209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>balance</th>\n",
       "      <td>0.005737</td>\n",
       "      <td>0.000232</td>\n",
       "      <td>24.736506</td>\n",
       "      <td>4.331521e-135</td>\n",
       "      <td>0.005282</td>\n",
       "      <td>0.006191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>income</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.369808</td>\n",
       "      <td>7.115254e-01</td>\n",
       "      <td>-0.000013</td>\n",
       "      <td>0.000019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>student2</th>\n",
       "      <td>-0.646776</td>\n",
       "      <td>0.236257</td>\n",
       "      <td>-2.737595</td>\n",
       "      <td>6.189022e-03</td>\n",
       "      <td>-1.109831</td>\n",
       "      <td>-0.183721</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Coef.  Std.Err.          z          P>|z|     [0.025    0.975]\n",
       "const    -10.869045  0.492273 -22.079320  4.995499e-108 -11.833882 -9.904209\n",
       "balance    0.005737  0.000232  24.736506  4.331521e-135   0.005282  0.006191\n",
       "income     0.000003  0.000008   0.369808   7.115254e-01  -0.000013  0.000019\n",
       "student2  -0.646776  0.236257  -2.737595   6.189022e-03  -1.109831 -0.183721"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = sm.add_constant(df[['balance', 'income', 'student2']])\n",
    "est = sm.Logit(y, X_train).fit()\n",
    "est.summary2().tables[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question \n",
    "1. Explain the values obtained especially in relation to the Z and p values above.\n",
    "\n",
    "### Answer\n",
    "For the Default data, estimated coefficients of the logistic regression model that predicts the probability of default using balance, income, and student status. Student status is encoded as a dummy variable student2, with a value of 1 for a student and a value of 0 for a non-student. In fitting this model, income was measured in thousands of dollars.\n",
    "The table above shows the coefficient estimates for a logistic regression model that uses balance, income (in thousands of dollars), and student status to predict probability of default. There is a surprising result here. The p values associated with balance and the dummy variable for student status are very small, indicating that each of these variables is associated with the probability of default. However, the coefficient for the dummy variable is negative, indicating that students are less likely to default than non students. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Discriminant Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>True default status</th>\n",
       "      <th>No</th>\n",
       "      <th>Yes</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted default status</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>No</th>\n",
       "      <td>9645</td>\n",
       "      <td>254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yes</th>\n",
       "      <td>22</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "True default status         No  Yes\n",
       "Predicted default status           \n",
       "No                        9645  254\n",
       "Yes                         22   79"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using scikit-learn\n",
    "X = df[['balance', 'income', 'student2']].to_numpy()\n",
    "y = df.default2.to_numpy()\n",
    "\n",
    "lda = LinearDiscriminantAnalysis(solver='svd')\n",
    "y_pred = lda.fit(X, y).predict(X)\n",
    "\n",
    "df_ = pd.DataFrame({'True default status': y,\n",
    "                    'Predicted default status': y_pred})\n",
    "df_.replace(to_replace={0:'No', 1:'Yes'}, inplace=True)\n",
    "\n",
    "df_.groupby(['Predicted default status','True default status']).size().unstack('True default status')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.97      1.00      0.99      9667\n",
      "         Yes       0.78      0.24      0.36       333\n",
      "\n",
      "    accuracy                           0.97     10000\n",
      "   macro avg       0.88      0.62      0.67     10000\n",
      "weighted avg       0.97      0.97      0.97     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y, y_pred, target_names=['No', 'Yes']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question \n",
    "The above code uses the entire dataset to perform the fit function (Note: the fit function is where the parameters are learnt). For proper testing and evaluation the training and test data should be separated. Edit the code above so that only training data are used for fit() and predict() uses test data that was not used in training. Print the results out as in the sample above.\n",
    "\n",
    "1. Comment on the results obtained, i.e. the difference in the results and the reasons for it (pg 145)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quadratic Discriminant Analysis\n",
    "\n",
    "QDA can be performed with code sample as below:\n",
    "```\n",
    "qda = QuadraticDiscriminantAnalysis()\n",
    "pred = qda.fit(X_train, y_train).predict(X_test)\n",
    "```\n",
    "\n",
    "KNN can be performed with code sample as below:\n",
    "```\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors=1)\n",
    "pred = knn.fit(X_train, y_train).predict(X_test)\n",
    "```\n",
    "The output from both can be printed:\n",
    "```\n",
    "print(confusion_matrix(y_test, pred).T)\n",
    "print(classification_report(y_test, pred, digits=3))\n",
    "```\n",
    "\n",
    "### Question \n",
    "Split the dataset into train and test as earlier. Run the QDA and KNN.\n",
    "1. Compare and comments on the results between LDA,QDA and KNN. \n",
    "1. How do we select what K is for KNN? Which K value is best? \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>True default status</th>\n",
       "      <th>No</th>\n",
       "      <th>Yes</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted default status</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>No</th>\n",
       "      <td>1925</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yes</th>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "True default status         No  Yes\n",
       "Predicted default status           \n",
       "No                        1925   58\n",
       "Yes                          6   11"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x = df[['balance', 'income', 'student2']].to_numpy()\n",
    "y = df.default2.to_numpy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "lda = LinearDiscriminantAnalysis(solver='svd')\n",
    "lda_pred = lda.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "df_ = pd.DataFrame({'True default status': y_test, \n",
    "                   'Predicted default status': lda_pred})\n",
    "\n",
    "df_.replace(to_replace={0:'No', 1:'Yes'}, inplace=True)\n",
    "\n",
    "df_.groupby(['Predicted default status','True default status']).size().unstack('True default status')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1927   68]\n",
      " [   4    1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.966     0.998     0.982      1931\n",
      "           1      0.200     0.014     0.027        69\n",
      "\n",
      "    accuracy                          0.964      2000\n",
      "   macro avg      0.583     0.506     0.504      2000\n",
      "weighted avg      0.939     0.964     0.949      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lda = LinearDiscriminantAnalysis(solver='svd')\n",
    "lda_pred = lda.fit(X_train, y_train).predict(X_test)\n",
    "print(confusion_matrix(y_test, pred).T)\n",
    "print(classification_report(y_test, pred, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1922   56]\n",
      " [   9   13]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.972     0.995     0.983      1931\n",
      "           1      0.591     0.188     0.286        69\n",
      "\n",
      "    accuracy                          0.968      2000\n",
      "   macro avg      0.781     0.592     0.635      2000\n",
      "weighted avg      0.959     0.968     0.959      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "qda = QuadraticDiscriminantAnalysis()\n",
    "pred = qda.fit(X_train, y_train).predict(X_test)\n",
    "print(confusion_matrix(y_test, pred).T)\n",
    "print(classification_report(y_test, pred, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = neighbors.KNeighborsClassifier(n_neighbors=1)\n",
    "pred = knn.fit(X_train, y_train).predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1880   50]\n",
      " [  51   19]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.974     0.974     0.974      1931\n",
      "           1      0.271     0.275     0.273        69\n",
      "\n",
      "    accuracy                          0.950      2000\n",
      "   macro avg      0.623     0.624     0.624      2000\n",
      "weighted avg      0.950     0.950     0.950      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, pred).T)\n",
    "print(classification_report(y_test, pred, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1924   61]\n",
      " [   7    8]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.969     0.996     0.983      1931\n",
      "           1      0.533     0.116     0.190        69\n",
      "\n",
      "    accuracy                          0.966      2000\n",
      "   macro avg      0.751     0.556     0.587      2000\n",
      "weighted avg      0.954     0.966     0.955      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn = neighbors.KNeighborsClassifier(n_neighbors=2)\n",
    "pred = knn.fit(X_train, y_train).predict(X_test)\n",
    "print(confusion_matrix(y_test, pred).T)\n",
    "print(classification_report(y_test, pred, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1915   55]\n",
      " [  16   14]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.972     0.992     0.982      1931\n",
      "           1      0.467     0.203     0.283        69\n",
      "\n",
      "    accuracy                          0.965      2000\n",
      "   macro avg      0.719     0.597     0.632      2000\n",
      "weighted avg      0.955     0.965     0.958      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn = neighbors.KNeighborsClassifier(n_neighbors=3)\n",
    "pred = knn.fit(X_train, y_train).predict(X_test)\n",
    "print(confusion_matrix(y_test, pred).T)\n",
    "print(classification_report(y_test, pred, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1924   62]\n",
      " [   7    7]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.969     0.996     0.982      1931\n",
      "           1      0.500     0.101     0.169        69\n",
      "\n",
      "    accuracy                          0.966      2000\n",
      "   macro avg      0.734     0.549     0.576      2000\n",
      "weighted avg      0.953     0.966     0.954      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn = neighbors.KNeighborsClassifier(n_neighbors=4)\n",
    "pred = knn.fit(X_train, y_train).predict(X_test)\n",
    "print(confusion_matrix(y_test, pred).T)\n",
    "print(classification_report(y_test, pred, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1924   57]\n",
      " [   7   12]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.971     0.996     0.984      1931\n",
      "           1      0.632     0.174     0.273        69\n",
      "\n",
      "    accuracy                          0.968      2000\n",
      "   macro avg      0.801     0.585     0.628      2000\n",
      "weighted avg      0.960     0.968     0.959      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn = neighbors.KNeighborsClassifier(n_neighbors=5)\n",
    "pred = knn.fit(X_train, y_train).predict(X_test)\n",
    "print(confusion_matrix(y_test, pred).T)\n",
    "print(classification_report(y_test, pred, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1924   62]\n",
      " [   7    7]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.969     0.996     0.982      1931\n",
      "           1      0.500     0.101     0.169        69\n",
      "\n",
      "    accuracy                          0.966      2000\n",
      "   macro avg      0.734     0.549     0.576      2000\n",
      "weighted avg      0.953     0.966     0.954      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn = neighbors.KNeighborsClassifier(n_neighbors=6)\n",
    "pred = knn.fit(X_train, y_train).predict(X_test)\n",
    "print(confusion_matrix(y_test, pred).T)\n",
    "print(classification_report(y_test, pred, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1922   62]\n",
      " [   9    7]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.969     0.995     0.982      1931\n",
      "           1      0.438     0.101     0.165        69\n",
      "\n",
      "    accuracy                          0.965      2000\n",
      "   macro avg      0.703     0.548     0.573      2000\n",
      "weighted avg      0.950     0.965     0.954      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn = neighbors.KNeighborsClassifier(n_neighbors=7)\n",
    "pred = knn.fit(X_train, y_train).predict(X_test)\n",
    "print(confusion_matrix(y_test, pred).T)\n",
    "print(classification_report(y_test, pred, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1925   65]\n",
      " [   6    4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.967     0.997     0.982      1931\n",
      "           1      0.400     0.058     0.101        69\n",
      "\n",
      "    accuracy                          0.965      2000\n",
      "   macro avg      0.684     0.527     0.542      2000\n",
      "weighted avg      0.948     0.965     0.952      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn = neighbors.KNeighborsClassifier(n_neighbors=8)\n",
    "pred = knn.fit(X_train, y_train).predict(X_test)\n",
    "print(confusion_matrix(y_test, pred).T)\n",
    "print(classification_report(y_test, pred, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1924   63]\n",
      " [   7    6]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.968     0.996     0.982      1931\n",
      "           1      0.462     0.087     0.146        69\n",
      "\n",
      "    accuracy                          0.965      2000\n",
      "   macro avg      0.715     0.542     0.564      2000\n",
      "weighted avg      0.951     0.965     0.953      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn = neighbors.KNeighborsClassifier(n_neighbors=9)\n",
    "pred = knn.fit(X_train, y_train).predict(X_test)\n",
    "print(confusion_matrix(y_test, pred).T)\n",
    "print(classification_report(y_test, pred, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1927   68]\n",
      " [   4    1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.966     0.998     0.982      1931\n",
      "           1      0.200     0.014     0.027        69\n",
      "\n",
      "    accuracy                          0.964      2000\n",
      "   macro avg      0.583     0.506     0.504      2000\n",
      "weighted avg      0.939     0.964     0.949      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn = neighbors.KNeighborsClassifier(n_neighbors=10)\n",
    "pred = knn.fit(X_train, y_train).predict(X_test)\n",
    "print(confusion_matrix(y_test, pred).T)\n",
    "print(classification_report(y_test, pred, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer\n",
    "1. Compare and comments on the results between LDA,QDA and KNN.\\\n",
    "The best results are obtained from QDA with an accuracy value: 0.968 \\\n",
    "However, for LDA and QDA it is not much different. The LDA accuracy value is: 0.964\\\n",
    "For the results given by KNN varies according to the number of Neigbors given, but the results are not much different from LDA and QDA, neighbor 1 has a value of: 0.950\n",
    "\n",
    "2. How do we select what K is for KNN? Which K value is be.\\\n",
    "There are no pre-defined statistical methods to find the most favorable value of K.\n",
    "Initialize a random K value and start computing. Choosing a small value of K leads to unstable decision boundaries. The substantial K value is better for classification as it leads to smoothening the decision boundaries. Derive a plot between error rate and K denoting values in a defined range. Then choose the K value as having a minimum error rate.\n",
    "In this case after tried 1-10 K,  the best result fro K is 5. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
